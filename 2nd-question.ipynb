{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11052434,"sourceType":"datasetVersion","datasetId":6885705}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import librosa\nimport numpy as np\nimport pandas as pd\nimport os\n\ndef get_audio_peaks(audio_path):\n    y, sr = librosa.load(audio_path)\n    # Compute onset strength envelope\n    onset_env = librosa.onset.onset_strength(y=y, sr=sr)\n    \n    # Pick peaks from onset envelope\n    peaks = librosa.util.peak_pick(onset_env,\n                                   pre_max=3,\n                                   post_max=3,\n                                   pre_avg=3,\n                                   post_avg=3,\n                                   delta=0.2,\n                                   wait=5)\n    \n    # Convert peak indices to timestamps\n    times = librosa.frames_to_time(peaks, sr=sr)\n    times = np.round(times, 2)\n    return times","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-03-18T05:13:48.041956Z","iopub.execute_input":"2025-03-18T05:13:48.042215Z","iopub.status.idle":"2025-03-18T05:13:49.314379Z","shell.execute_reply.started":"2025-03-18T05:13:48.042188Z","shell.execute_reply":"2025-03-18T05:13:49.313149Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"def detect_frame_boundaries(frame):\n    # Convert frame to grayscale\n    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n    \n    # Apply Canny edge detection\n    edges = cv2.Canny(gray_frame, 50, 150)\n    \n    # Find contours in the edge-detected image\n    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    \n    for contour in contours:\n        # Approximate contour to a polygon\n        approx = cv2.approxPolyDP(contour, 0.01 * cv2.arcLength(contour, True), True)\n        \n        # Check if it is a rectangle (4 corners)\n        if len(approx) == 4:\n            x, y, w, h = cv2.boundingRect(approx)  # Get bounding box of rectangle\n            return x, y, w, h  # Return rectangle boundaries\n    \n    return None  # Return None if no rectangle is found","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-03-18T05:13:53.883141Z","iopub.execute_input":"2025-03-18T05:13:53.883479Z","iopub.status.idle":"2025-03-18T05:13:53.889199Z","shell.execute_reply.started":"2025-03-18T05:13:53.883452Z","shell.execute_reply":"2025-03-18T05:13:53.888092Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def detect_collisions_with_frame(video_path):\n    cap = cv2.VideoCapture(video_path)\n    \n    if not cap.isOpened():\n        print(f\"Error: Unable to open video file at {video_path}\")\n        return []\n    \n    impacts = []  # List to store timestamps of collisions\n    fps = cap.get(cv2.CAP_PROP_FPS)  # Frames per second\n    frame_count = 0\n    \n    rect_boundaries = None  # To store detected rectangular frame boundaries\n    \n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            break\n        \n        # Detect rectangular frame in the first frame\n        if rect_boundaries is None:\n            rect_boundaries = detect_frame_boundaries(frame)\n            if rect_boundaries is None:\n                rect_boundaries = [50, 34, 341, 223]\n                break\n        \n        x_rect, y_rect, w_rect, h_rect = rect_boundaries\n        \n        # Convert frame to HSV for better color segmentation\n        hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n        \n        # Define HSV range for detecting the blue ball\n        lower_blue = np.array([100, 150, 50])  # Adjust these values if needed\n        upper_blue = np.array([140, 255, 255])\n        \n        # Create a mask for the blue ball\n        mask = cv2.inRange(hsv_frame, lower_blue, upper_blue)\n        \n        # Find contours in the mask\n        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        \n        if contours:\n            # Select the largest contour (assumed to be the ball)\n            largest_contour = max(contours, key=cv2.contourArea)\n            x_ball, y_ball, w_ball, h_ball = cv2.boundingRect(largest_contour)  # Get bounding box\n            \n            # Calculate center of the ball\n            ball_center_x = x_ball + w_ball // 2\n            ball_center_y = y_ball + h_ball // 2\n            \n            # Check for collisions with edges of the rectangular frame\n            if (\n                ball_center_x - 6 <= x_rect or ball_center_x + 6 >= x_rect + w_rect or  # Left or right edge of rectangle\n                ball_center_y - 6 <= y_rect     # Bottom edge of rectangle\n            ):\n                impact_time = round(frame_count / fps, 2)  # Calculate timestamp in seconds and round to 2 decimal places\n                \n                # Add timestamp only if it's at least 0.25 seconds apart from the last recorded impact\n                if len(impacts) == 0 or (impact_time - impacts[-1] >= 0.25):\n                    impacts.append(impact_time)\n        \n        frame_count += 1\n    \n    cap.release()\n    return impacts","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-03-18T05:14:00.106288Z","iopub.execute_input":"2025-03-18T05:14:00.106763Z","iopub.status.idle":"2025-03-18T05:14:00.116300Z","shell.execute_reply.started":"2025-03-18T05:14:00.106723Z","shell.execute_reply":"2025-03-18T05:14:00.115123Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/video-audio-match/dataset/submit_solution_mapping.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T05:15:25.491240Z","iopub.execute_input":"2025-03-18T05:15:25.491626Z","iopub.status.idle":"2025-03-18T05:15:25.509284Z","shell.execute_reply.started":"2025-03-18T05:15:25.491596Z","shell.execute_reply":"2025-03-18T05:15:25.508227Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-03-18T05:15:27.579738Z","iopub.execute_input":"2025-03-18T05:15:27.580112Z","iopub.status.idle":"2025-03-18T05:15:27.612533Z","shell.execute_reply.started":"2025-03-18T05:15:27.580083Z","shell.execute_reply":"2025-03-18T05:15:27.611335Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 45 entries, 0 to 44\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   AUDIO   45 non-null     object \n 1   VIDEO   0 non-null      float64\ndtypes: float64(1), object(1)\nmemory usage: 848.0+ bytes\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import os\n\n# Function to generate audio timestamps for all audio files\ndef generate_audio_timestamps(audio_folder):\n    audio_timestamps = {}\n    for audio_file in os.listdir(audio_folder):\n        if audio_file.endswith('.wav'):\n            # Replace this with your function to extract audio timestamps\n            timestamps = get_audio_peaks(os.path.join(audio_folder, audio_file))\n            audio_timestamps[audio_file] = timestamps\n    return audio_timestamps\n\n# Function to generate video timestamps for all video files\ndef generate_video_timestamps(video_folder):\n    video_timestamps = {}\n    for video_file in os.listdir(video_folder):\n        if video_file.endswith('.mp4'):\n            # Replace this with your function to extract video timestamps\n            timestamps = detect_collisions_with_frame(os.path.join(video_folder, video_file))\n            video_timestamps[video_file] = timestamps\n    return video_timestamps\n","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-03-18T05:15:30.135162Z","iopub.execute_input":"2025-03-18T05:15:30.135589Z","iopub.status.idle":"2025-03-18T05:15:30.142089Z","shell.execute_reply.started":"2025-03-18T05:15:30.135550Z","shell.execute_reply":"2025-03-18T05:15:30.141087Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import cv2\n# Example usage\naudio_folder = '/kaggle/input/video-audio-match/dataset/audio_only'\nvideo_folder = '/kaggle/input/video-audio-match/dataset/video_only'\n\naudio_timestamps_dict = generate_audio_timestamps(audio_folder)\nvideo_timestamps_dict = generate_video_timestamps(video_folder)\n\nprint(len(audio_timestamps_dict))\nprint(len(video_timestamps_dict))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-18T05:16:37.917140Z","iopub.execute_input":"2025-03-18T05:16:37.917540Z","iopub.status.idle":"2025-03-18T05:17:28.668222Z","shell.execute_reply.started":"2025-03-18T05:16:37.917485Z","shell.execute_reply":"2025-03-18T05:17:28.667307Z"}},"outputs":[{"name":"stdout","text":"45\n45\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"def compute_matching_cost(audio_timestamps, video_timestamps):\n    \"\"\"\n    Compute the cost of matching an audio file with a video file.\n    The cost is defined as the sum of absolute differences between closest timestamps.\n    \"\"\"\n    if not video_timestamps:  # Handle empty list case\n        return float('inf')  # Assign a high cost when no match is possible\n\n    cost = sum(abs(min(video_timestamps, key=lambda x: abs(x - a_time)) - a_time) for a_time in audio_timestamps)\n    return cost\n ","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-03-18T05:17:39.227279Z","iopub.execute_input":"2025-03-18T05:17:39.227661Z","iopub.status.idle":"2025-03-18T05:17:39.233750Z","shell.execute_reply.started":"2025-03-18T05:17:39.227632Z","shell.execute_reply":"2025-03-18T05:17:39.232615Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def one_to_one_matching(audio_timestamps_dict, video_timestamps_dict):\n    \"\"\"\n    Perform 1-to-1 matching between audio files and video files based on timestamp similarity.\n    Returns a dictionary where keys are audio filenames and values are matched video filenames.\n    \"\"\"\n    # Create a list of all possible pairs (audio, video) with their costs\n    pairs = []\n    for audio_file, audio_timestamps in audio_timestamps_dict.items():\n        for video_file, video_timestamps in video_timestamps_dict.items():\n            cost = compute_matching_cost(audio_timestamps, video_timestamps)\n            pairs.append((audio_file, video_file, cost))\n    \n    # Sort pairs by cost (ascending order)\n    pairs.sort(key=lambda x: x[2])\n    \n    # Perform greedy matching\n    matched_audio = set()\n    matched_video = set()\n    matches = {}\n\n    for audio_file, video_file, cost in pairs:\n        if audio_file not in matched_audio and video_file not in matched_video:\n            matches[audio_file] = video_file\n            matched_audio.add(audio_file)\n            matched_video.add(video_file)\n    \n    return matches\n","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-03-18T05:17:40.292262Z","iopub.execute_input":"2025-03-18T05:17:40.292667Z","iopub.status.idle":"2025-03-18T05:17:40.299700Z","shell.execute_reply.started":"2025-03-18T05:17:40.292635Z","shell.execute_reply":"2025-03-18T05:17:40.298129Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def update_dataframe_with_matches(df, matches_dict):\n    \"\"\"\n    Update the VIDEO column of the DataFrame with matched video filenames.\n    \"\"\"\n    for index, row in df.iterrows():\n        audio_file = row['AUDIO']\n        if audio_file in matches_dict:\n            df.at[index, 'VIDEO'] = matches_dict[audio_file]\n    \n    return df","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-03-18T05:17:41.205384Z","iopub.execute_input":"2025-03-18T05:17:41.205749Z","iopub.status.idle":"2025-03-18T05:17:41.210998Z","shell.execute_reply.started":"2025-03-18T05:17:41.205720Z","shell.execute_reply":"2025-03-18T05:17:41.209823Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"matches_dict = one_to_one_matching(audio_timestamps_dict, video_timestamps_dict)\n\n# Update DataFrame with matches\ndf = update_dataframe_with_matches(df, matches_dict)\n\n# Save updated DataFrame to CSV\ndf.to_csv('audio_video_matches.csv', index=False)\n\nprint(\"Updated DataFrame:\")\nprint(df)","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-03-18T05:17:42.350371Z","iopub.execute_input":"2025-03-18T05:17:42.350721Z","iopub.status.idle":"2025-03-18T05:17:42.517695Z","shell.execute_reply.started":"2025-03-18T05:17:42.350696Z","shell.execute_reply":"2025-03-18T05:17:42.516610Z"}},"outputs":[{"name":"stdout","text":"Updated DataFrame:\n                   AUDIO                 VIDEO\n0    audio_only_ID_6.wav  video_only_ID_32.mp4\n1   audio_only_ID_34.wav  video_only_ID_27.mp4\n2   audio_only_ID_27.wav  video_only_ID_40.mp4\n3   audio_only_ID_29.wav  video_only_ID_10.mp4\n4   audio_only_ID_41.wav  video_only_ID_37.mp4\n5   audio_only_ID_13.wav  video_only_ID_14.mp4\n6   audio_only_ID_32.wav  video_only_ID_41.mp4\n7   audio_only_ID_45.wav  video_only_ID_25.mp4\n8   audio_only_ID_36.wav  video_only_ID_13.mp4\n9   audio_only_ID_44.wav  video_only_ID_36.mp4\n10  audio_only_ID_40.wav   video_only_ID_5.mp4\n11   audio_only_ID_9.wav  video_only_ID_17.mp4\n12   audio_only_ID_2.wav  video_only_ID_16.mp4\n13  audio_only_ID_30.wav  video_only_ID_28.mp4\n14  audio_only_ID_19.wav  video_only_ID_35.mp4\n15  audio_only_ID_20.wav  video_only_ID_39.mp4\n16  audio_only_ID_43.wav  video_only_ID_21.mp4\n17  audio_only_ID_11.wav   video_only_ID_7.mp4\n18   audio_only_ID_7.wav   video_only_ID_2.mp4\n19  audio_only_ID_23.wav   video_only_ID_6.mp4\n20  audio_only_ID_18.wav   video_only_ID_4.mp4\n21  audio_only_ID_14.wav  video_only_ID_12.mp4\n22  audio_only_ID_17.wav  video_only_ID_29.mp4\n23  audio_only_ID_39.wav  video_only_ID_19.mp4\n24  audio_only_ID_10.wav  video_only_ID_42.mp4\n25  audio_only_ID_22.wav  video_only_ID_20.mp4\n26  audio_only_ID_15.wav  video_only_ID_18.mp4\n27   audio_only_ID_4.wav  video_only_ID_43.mp4\n28  audio_only_ID_37.wav   video_only_ID_1.mp4\n29   audio_only_ID_5.wav  video_only_ID_38.mp4\n30   audio_only_ID_3.wav  video_only_ID_24.mp4\n31  audio_only_ID_35.wav  video_only_ID_22.mp4\n32  audio_only_ID_38.wav   video_only_ID_8.mp4\n33  audio_only_ID_21.wav  video_only_ID_34.mp4\n34   audio_only_ID_8.wav  video_only_ID_23.mp4\n35  audio_only_ID_42.wav   video_only_ID_9.mp4\n36  audio_only_ID_25.wav   video_only_ID_3.mp4\n37  audio_only_ID_28.wav  video_only_ID_45.mp4\n38  audio_only_ID_12.wav  video_only_ID_33.mp4\n39  audio_only_ID_16.wav  video_only_ID_11.mp4\n40  audio_only_ID_26.wav  video_only_ID_30.mp4\n41   audio_only_ID_1.wav  video_only_ID_15.mp4\n42  audio_only_ID_31.wav  video_only_ID_26.mp4\n43  audio_only_ID_24.wav  video_only_ID_44.mp4\n44  audio_only_ID_33.wav  video_only_ID_31.mp4\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-12-2c53852d543e>:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'video_only_ID_32.mp4' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n  df.at[index, 'VIDEO'] = matches_dict[audio_file]\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"output_file_path = '/kaggle/working/audio_video_matches.csv'  # Path to save the file\n\n# Save the DataFrame to a CSV file\ndf.to_csv(output_file_path, index=False)\n\nprint(f\"DataFrame saved successfully to {output_file_path}.\")\n","metadata":{"trusted":true,"editable":false,"execution":{"iopub.status.busy":"2025-03-18T05:18:00.381307Z","iopub.execute_input":"2025-03-18T05:18:00.381671Z","iopub.status.idle":"2025-03-18T05:18:00.389243Z","shell.execute_reply.started":"2025-03-18T05:18:00.381642Z","shell.execute_reply":"2025-03-18T05:18:00.388116Z"}},"outputs":[{"name":"stdout","text":"DataFrame saved successfully to /kaggle/working/audio_video_matches.csv.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}